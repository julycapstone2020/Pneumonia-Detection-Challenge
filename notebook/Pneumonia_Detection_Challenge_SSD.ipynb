{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pneumonia-Detection-Challenge-SSD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4Q+ycTzRZQU/rDLkAgxUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julycapstone2020/Pneumonia-Detection-Challenge/blob/development/notebook/Pneumonia_Detection_Challenge_SSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hayxjwxN-_Ab",
        "colab_type": "text"
      },
      "source": [
        "# End-to-End Pneumonia Detection \n",
        "\n",
        "This notebook build an end-to-end build a pneumonia detection system, to locate the position of inflammation in an image.\n",
        "\n",
        "Tissues with sparse material, such as lungs which are full of air, do not absorb the X-rays and appear black in the image. Dense tissues such as bones absorb X-rays and appear white in the image.\n",
        "\n",
        "While we are theoretically detecting `lung opacities`, there are lung opacities that are not pneumonia related.\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "To locate the position of inflammation in an image.\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "In the data, some of these are labeled `Not Normal No Lung Opacity`.This extra third class indicates that while pneumonia was determined not to be present, there was nonetheless some type of abnormality on the image and oftentimes this finding may mimic the appearance of true pneumonia.\n",
        "\n",
        "Dicom original images: -Medical images are stored in a special format called DICOM files `(*.dcm)`. They contain a combination of header metadata as well as underlying raw image arrays for pixel data.Details about the data and dataset files are given in below link,\n",
        "\n",
        "https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data\n",
        "\n",
        "### Pre-Processing, Data Visualization, EDA \n",
        "\n",
        "* Exploring the given Data files, classes and images of different classes.\n",
        "* Dealing with missing values\n",
        "* Visualizationof different classes \n",
        "* Analysis from the visualizationof different classes\n",
        "\n",
        "\n",
        "### Model Building \n",
        "\n",
        "* Building a pneumonia detection model starting from basic CNN and then improving upon it.\n",
        "* Train the model\n",
        "* To deal with large training time, save the weights so that you can use them when training the model for the second time without starting from scratch\n",
        "\n",
        "\n",
        "### Test the Model, Fine-tuning and Repeat\n",
        "\n",
        "* Test the model and report as per evaluation metrics\n",
        "* Try different models\n",
        "* Set different hyper parameters, by trying different optimizers, loss functions, epochs, learning rate, batch size, checkpointing, early stopping etc. for these models to fine-tune them\n",
        "* Report evaluation metrics for these modelsalong with your observation on how changing different hyper parameters leads to change in the final evaluation metric.\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "\n",
        "\n",
        "## 4. Features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3xU42fs-rZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "650148b5-e3ac-48d1-f1dd-7d71e29d11f8"
      },
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMcncLKyBDA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8ed556a0-bd54-44e3-d859-ff103b78d2df"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "%tensorflow_version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Currently selected TF version: 1.x\n",
            "Available versions:\n",
            "* 1.x\n",
            "* 2.x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pBxX2-WPkrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "16213ae1-b4a2-4108-88e2-3ed07571f2a8"
      },
      "source": [
        "# Install 2.1.0 for saving model\n",
        "!pip install q keras==2.0.4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: keras==2.0.4 in /usr/local/lib/python3.6/dist-packages (2.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.4) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==2.0.4) (1.15.0)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==2.0.4) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.4) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.4) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksvqyI3rPrda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "307ef193-8d5b-4f07-c8ce-3f4d35375c26"
      },
      "source": [
        "!git clone https://github.com/pierluigiferrari/ssd_keras"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ssd_keras' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5ymCEWmUoUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7042009-f468-422d-9c21-cf0602e4f5c2"
      },
      "source": [
        "!ls "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  ssd_keras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEMfC9CoV9_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/ssd_keras')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XODVfKzTWPz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "35125154-3d7b-42e1-eb29-6e19721ee3de"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bounding_box_utils   README.md\n",
            "CONTRIBUTING.md      ssd300_evaluation_COCO.ipynb\n",
            "data_generator\t     ssd300_evaluation.ipynb\n",
            "eval_utils\t     ssd300_inference.ipynb\n",
            "examples\t     ssd300_pneumonia_training_log.csv\n",
            "__init__.py\t     ssd300_training.ipynb\n",
            "ISSUE_TEMPLATE.md    ssd512_inference.ipynb\n",
            "keras_layers\t     ssd7_training.ipynb\n",
            "keras_loss_function  ssd_encoder_decoder\n",
            "LICENSE.txt\t     ssd_keras\n",
            "misc_utils\t     training_summaries\n",
            "models\t\t     weight_sampling_tutorial.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPiMMbvFPlN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e29ff97b-888a-4035-ec02-123a740984f6"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from models.keras_ssd300 import ssd_300\n",
        "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
        "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
        "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
        "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
        "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
        "\n",
        "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
        "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
        "\n",
        "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
        "from data_generator.object_detection_2d_geometric_ops import Resize\n",
        "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
        "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
        "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
        "from eval_utils.average_precision_evaluator import Evaluator\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEZJzYCiU2wM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height = 300 # Height of the model input images\n",
        "img_width = 300 # Width of the model input images\n",
        "img_channels = 3 # Number of color channels of the model input images\n",
        "mean_color = [123, 117, 104] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
        "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
        "n_classes = 2 # Number of positive classes\n",
        "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
        "scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
        "scales = scales_pascal\n",
        "aspect_ratios = [[1.0, 2.0, 0.5],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5],\n",
        "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
        "two_boxes_for_ar1 = True\n",
        "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
        "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
        "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
        "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
        "normalize_coords = True\n",
        "model_mode = 'training'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mryhr_0rXeqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Cur_Directory = '/content/drive/My Drive/Pneumonia Detection/SSD Models'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVVVpMVBYiMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WeightFile = os.path.join(Cur_Directory,\"VGG_ILSVRC_16_layers_fc_reduced.h5\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7L90PgfYjdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "867a2966-420e-4fed-88e1-df9ae6fad9e6"
      },
      "source": [
        "# 1: Build the Keras model.\n",
        "\n",
        "#K.clear_session() # Clear previous models from memory.\n",
        "\n",
        "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
        "                n_classes=n_classes,\n",
        "                mode='training',\n",
        "                l2_regularization=0.0005,\n",
        "                scales=scales,\n",
        "                aspect_ratios_per_layer=aspect_ratios,\n",
        "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                steps=steps,\n",
        "                offsets=offsets,\n",
        "                clip_boxes=clip_boxes,\n",
        "                variances=variances,\n",
        "                normalize_coords=normalize_coords,\n",
        "                subtract_mean=mean_color,\n",
        "                swap_channels=swap_channels)\n",
        "\n",
        "# 2: Load some weights into the model.\n",
        "\n",
        "# TODO: Set the path to the weights you want to load.\n",
        "weights_path = os.path.join(Cur_Directory,\"VGG_ILSVRC_16_layers_fc_reduced.h5\")\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
        "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
        "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
        "\n",
        "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "# sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
        "\n",
        "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
        "\n",
        "model.compile(optimizer='adam', loss=ssd_loss.compute_loss)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:55: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:391: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3425: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1150: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3245: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2852: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1114: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:150: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:155: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:160: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:329: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:337: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ssd_keras/keras_loss_function/keras_ssd_loss.py:95: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/ssd_keras/keras_loss_function/keras_ssd_loss.py:133: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/ssd_keras/keras_loss_function/keras_ssd_loss.py:74: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/ssd_keras/keras_loss_function/keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHdendjZYmBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save(os.path.join(Cur_Directory,\"model_ssd_initial_1.h5\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHbxdtysY2dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_path = os.path.join(Cur_Directory,\"model_ssd_initial_1.h5\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRDX97uAGcin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_trained = os.path.join(Cur_Directory,\"ssd300_pneumonia_epoch-39_loss-4.3320_val_loss-4.2565.h5\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVKShvmcGnxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
        "\n",
        "# #K.clear_session() # Clear previous models from memory.\n",
        "\n",
        "# model = load_model(model_trained, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
        "#                                                'L2Normalization': L2Normalization,\n",
        "#                                                'compute_loss': ssd_loss.compute_loss})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py7Vs2aLGtUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82d14588-ba94-4c8d-8c33-e9ef0e709250"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "input_1 (InputLayer)             (None, 300, 300, 3)   0                                            \n",
            "____________________________________________________________________________________________________\n",
            "identity_layer (Lambda)          (None, 300, 300, 3)   0           input_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "input_mean_normalization (Lambda (None, 300, 300, 3)   0           identity_layer[0][0]             \n",
            "____________________________________________________________________________________________________\n",
            "input_channel_swap (Lambda)      (None, 300, 300, 3)   0           input_mean_normalization[0][0]   \n",
            "____________________________________________________________________________________________________\n",
            "conv1_1 (Conv2D)                 (None, 300, 300, 64)  1792        input_channel_swap[0][0]         \n",
            "____________________________________________________________________________________________________\n",
            "conv1_2 (Conv2D)                 (None, 300, 300, 64)  36928       conv1_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)             (None, 150, 150, 64)  0           conv1_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv2_1 (Conv2D)                 (None, 150, 150, 128) 73856       pool1[0][0]                      \n",
            "____________________________________________________________________________________________________\n",
            "conv2_2 (Conv2D)                 (None, 150, 150, 128) 147584      conv2_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "pool2 (MaxPooling2D)             (None, 75, 75, 128)   0           conv2_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv3_1 (Conv2D)                 (None, 75, 75, 256)   295168      pool2[0][0]                      \n",
            "____________________________________________________________________________________________________\n",
            "conv3_2 (Conv2D)                 (None, 75, 75, 256)   590080      conv3_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv3_3 (Conv2D)                 (None, 75, 75, 256)   590080      conv3_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "pool3 (MaxPooling2D)             (None, 38, 38, 256)   0           conv3_3[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv4_1 (Conv2D)                 (None, 38, 38, 512)   1180160     pool3[0][0]                      \n",
            "____________________________________________________________________________________________________\n",
            "conv4_2 (Conv2D)                 (None, 38, 38, 512)   2359808     conv4_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3 (Conv2D)                 (None, 38, 38, 512)   2359808     conv4_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "pool4 (MaxPooling2D)             (None, 19, 19, 512)   0           conv4_3[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv5_1 (Conv2D)                 (None, 19, 19, 512)   2359808     pool4[0][0]                      \n",
            "____________________________________________________________________________________________________\n",
            "conv5_2 (Conv2D)                 (None, 19, 19, 512)   2359808     conv5_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv5_3 (Conv2D)                 (None, 19, 19, 512)   2359808     conv5_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "pool5 (MaxPooling2D)             (None, 19, 19, 512)   0           conv5_3[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "fc6 (Conv2D)                     (None, 19, 19, 1024)  4719616     pool5[0][0]                      \n",
            "____________________________________________________________________________________________________\n",
            "fc7 (Conv2D)                     (None, 19, 19, 1024)  1049600     fc6[0][0]                        \n",
            "____________________________________________________________________________________________________\n",
            "conv6_1 (Conv2D)                 (None, 19, 19, 256)   262400      fc7[0][0]                        \n",
            "____________________________________________________________________________________________________\n",
            "conv6_padding (ZeroPadding2D)    (None, 21, 21, 256)   0           conv6_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv6_2 (Conv2D)                 (None, 10, 10, 512)   1180160     conv6_padding[0][0]              \n",
            "____________________________________________________________________________________________________\n",
            "conv7_1 (Conv2D)                 (None, 10, 10, 128)   65664       conv6_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv7_padding (ZeroPadding2D)    (None, 12, 12, 128)   0           conv7_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv7_2 (Conv2D)                 (None, 5, 5, 256)     295168      conv7_padding[0][0]              \n",
            "____________________________________________________________________________________________________\n",
            "conv8_1 (Conv2D)                 (None, 5, 5, 128)     32896       conv7_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv8_2 (Conv2D)                 (None, 3, 3, 256)     295168      conv8_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv9_1 (Conv2D)                 (None, 3, 3, 128)     32896       conv8_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3_norm (L2Normalization)   (None, 38, 38, 512)   512         conv4_3[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv9_2 (Conv2D)                 (None, 1, 1, 256)     295168      conv9_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3_norm_mbox_conf (Conv2D)  (None, 38, 38, 12)    55308       conv4_3_norm[0][0]               \n",
            "____________________________________________________________________________________________________\n",
            "fc7_mbox_conf (Conv2D)           (None, 19, 19, 18)    165906      fc7[0][0]                        \n",
            "____________________________________________________________________________________________________\n",
            "conv6_2_mbox_conf (Conv2D)       (None, 10, 10, 18)    82962       conv6_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv7_2_mbox_conf (Conv2D)       (None, 5, 5, 18)      41490       conv7_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv8_2_mbox_conf (Conv2D)       (None, 3, 3, 12)      27660       conv8_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv9_2_mbox_conf (Conv2D)       (None, 1, 1, 12)      27660       conv9_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3_norm_mbox_loc (Conv2D)   (None, 38, 38, 16)    73744       conv4_3_norm[0][0]               \n",
            "____________________________________________________________________________________________________\n",
            "fc7_mbox_loc (Conv2D)            (None, 19, 19, 24)    221208      fc7[0][0]                        \n",
            "____________________________________________________________________________________________________\n",
            "conv6_2_mbox_loc (Conv2D)        (None, 10, 10, 24)    110616      conv6_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv7_2_mbox_loc (Conv2D)        (None, 5, 5, 24)      55320       conv7_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv8_2_mbox_loc (Conv2D)        (None, 3, 3, 16)      36880       conv8_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv9_2_mbox_loc (Conv2D)        (None, 1, 1, 16)      36880       conv9_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3_norm_mbox_conf_reshape ( (None, 5776, 3)       0           conv4_3_norm_mbox_conf[0][0]     \n",
            "____________________________________________________________________________________________________\n",
            "fc7_mbox_conf_reshape (Reshape)  (None, 2166, 3)       0           fc7_mbox_conf[0][0]              \n",
            "____________________________________________________________________________________________________\n",
            "conv6_2_mbox_conf_reshape (Resha (None, 600, 3)        0           conv6_2_mbox_conf[0][0]          \n",
            "____________________________________________________________________________________________________\n",
            "conv7_2_mbox_conf_reshape (Resha (None, 150, 3)        0           conv7_2_mbox_conf[0][0]          \n",
            "____________________________________________________________________________________________________\n",
            "conv8_2_mbox_conf_reshape (Resha (None, 36, 3)         0           conv8_2_mbox_conf[0][0]          \n",
            "____________________________________________________________________________________________________\n",
            "conv9_2_mbox_conf_reshape (Resha (None, 4, 3)          0           conv9_2_mbox_conf[0][0]          \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3_norm_mbox_priorbox (Anch (None, 38, 38, 4, 8)  0           conv4_3_norm_mbox_loc[0][0]      \n",
            "____________________________________________________________________________________________________\n",
            "fc7_mbox_priorbox (AnchorBoxes)  (None, 19, 19, 6, 8)  0           fc7_mbox_loc[0][0]               \n",
            "____________________________________________________________________________________________________\n",
            "conv6_2_mbox_priorbox (AnchorBox (None, 10, 10, 6, 8)  0           conv6_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "conv7_2_mbox_priorbox (AnchorBox (None, 5, 5, 6, 8)    0           conv7_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "conv8_2_mbox_priorbox (AnchorBox (None, 3, 3, 4, 8)    0           conv8_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "conv9_2_mbox_priorbox (AnchorBox (None, 1, 1, 4, 8)    0           conv9_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "mbox_conf (Concatenate)          (None, 8732, 3)       0           conv4_3_norm_mbox_conf_reshape[0]\n",
            "                                                                   fc7_mbox_conf_reshape[0][0]      \n",
            "                                                                   conv6_2_mbox_conf_reshape[0][0]  \n",
            "                                                                   conv7_2_mbox_conf_reshape[0][0]  \n",
            "                                                                   conv8_2_mbox_conf_reshape[0][0]  \n",
            "                                                                   conv9_2_mbox_conf_reshape[0][0]  \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3_norm_mbox_loc_reshape (R (None, 5776, 4)       0           conv4_3_norm_mbox_loc[0][0]      \n",
            "____________________________________________________________________________________________________\n",
            "fc7_mbox_loc_reshape (Reshape)   (None, 2166, 4)       0           fc7_mbox_loc[0][0]               \n",
            "____________________________________________________________________________________________________\n",
            "conv6_2_mbox_loc_reshape (Reshap (None, 600, 4)        0           conv6_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "conv7_2_mbox_loc_reshape (Reshap (None, 150, 4)        0           conv7_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "conv8_2_mbox_loc_reshape (Reshap (None, 36, 4)         0           conv8_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "conv9_2_mbox_loc_reshape (Reshap (None, 4, 4)          0           conv9_2_mbox_loc[0][0]           \n",
            "____________________________________________________________________________________________________\n",
            "conv4_3_norm_mbox_priorbox_resha (None, 5776, 8)       0           conv4_3_norm_mbox_priorbox[0][0] \n",
            "____________________________________________________________________________________________________\n",
            "fc7_mbox_priorbox_reshape (Resha (None, 2166, 8)       0           fc7_mbox_priorbox[0][0]          \n",
            "____________________________________________________________________________________________________\n",
            "conv6_2_mbox_priorbox_reshape (R (None, 600, 8)        0           conv6_2_mbox_priorbox[0][0]      \n",
            "____________________________________________________________________________________________________\n",
            "conv7_2_mbox_priorbox_reshape (R (None, 150, 8)        0           conv7_2_mbox_priorbox[0][0]      \n",
            "____________________________________________________________________________________________________\n",
            "conv8_2_mbox_priorbox_reshape (R (None, 36, 8)         0           conv8_2_mbox_priorbox[0][0]      \n",
            "____________________________________________________________________________________________________\n",
            "conv9_2_mbox_priorbox_reshape (R (None, 4, 8)          0           conv9_2_mbox_priorbox[0][0]      \n",
            "____________________________________________________________________________________________________\n",
            "mbox_conf_softmax (Activation)   (None, 8732, 3)       0           mbox_conf[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "mbox_loc (Concatenate)           (None, 8732, 4)       0           conv4_3_norm_mbox_loc_reshape[0][\n",
            "                                                                   fc7_mbox_loc_reshape[0][0]       \n",
            "                                                                   conv6_2_mbox_loc_reshape[0][0]   \n",
            "                                                                   conv7_2_mbox_loc_reshape[0][0]   \n",
            "                                                                   conv8_2_mbox_loc_reshape[0][0]   \n",
            "                                                                   conv9_2_mbox_loc_reshape[0][0]   \n",
            "____________________________________________________________________________________________________\n",
            "mbox_priorbox (Concatenate)      (None, 8732, 8)       0           conv4_3_norm_mbox_priorbox_reshap\n",
            "                                                                   fc7_mbox_priorbox_reshape[0][0]  \n",
            "                                                                   conv6_2_mbox_priorbox_reshape[0][\n",
            "                                                                   conv7_2_mbox_priorbox_reshape[0][\n",
            "                                                                   conv8_2_mbox_priorbox_reshape[0][\n",
            "                                                                   conv9_2_mbox_priorbox_reshape[0][\n",
            "____________________________________________________________________________________________________\n",
            "predictions (Concatenate)        (None, 8732, 15)      0           mbox_conf_softmax[0][0]          \n",
            "                                                                   mbox_loc[0][0]                   \n",
            "                                                                   mbox_priorbox[0][0]              \n",
            "====================================================================================================\n",
            "Total params: 23,879,570\n",
            "Trainable params: 23,879,570\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq790Z4dg_0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "26355de4-fa33-4cda-b741-a9bb4a81cc5c"
      },
      "source": [
        "!ls "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bounding_box_utils   README.md\n",
            "CONTRIBUTING.md      ssd300_evaluation_COCO.ipynb\n",
            "data_generator\t     ssd300_evaluation.ipynb\n",
            "eval_utils\t     ssd300_inference.ipynb\n",
            "examples\t     ssd300_pneumonia_training_log.csv\n",
            "__init__.py\t     ssd300_training.ipynb\n",
            "ISSUE_TEMPLATE.md    ssd512_inference.ipynb\n",
            "keras_layers\t     ssd7_training.ipynb\n",
            "keras_loss_function  ssd_encoder_decoder\n",
            "LICENSE.txt\t     ssd_keras\n",
            "misc_utils\t     training_summaries\n",
            "models\t\t     weight_sampling_tutorial.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y8Ig9o1I_zI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0ec42e9c-5a60-412c-fd0a-7b7f0ec993d7"
      },
      "source": [
        "# Checkout the labels of our data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "PROJECT_DIR = \"/content/drive/My Drive/Pneumonia Detection\"\n",
        "\n",
        "# /content/drive/My Drive/Pneumonia Detection/stage_2_train_labels.csv\n",
        "# /content/drive/My Drive/Pneumonia Detection/stage_2_detailed_class_info.csv\n",
        "\n",
        "print(os.path.join(PROJECT_DIR , 'stage_2_detailed_class_info.csv'))\n",
        "\n",
        "class_info_df = pd.read_csv(os.path.join(PROJECT_DIR , 'stage_2_detailed_class_info.csv'))\n",
        "train_labels_df = pd.read_csv(os.path.join(PROJECT_DIR , 'stage_2_train_labels.csv'))\n",
        "\n",
        "print(f\"Detailed class info -  rows: {class_info_df.shape[0]}, columns: {class_info_df.shape[1]}\")\n",
        "print(f\"Train labels -  rows: {train_labels_df.shape[0]}, columns: {train_labels_df.shape[1]}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Pneumonia Detection/stage_2_detailed_class_info.csv\n",
            "Detailed class info -  rows: 30227, columns: 2\n",
            "Train labels -  rows: 30227, columns: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl_27RIrJoC6",
        "colab_type": "text"
      },
      "source": [
        "### Merge both `class info` and `train labels` into one dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu5VWdunJrM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_class_df = train_labels_df.merge(class_info_df, left_on='patientId', right_on='patientId', how='inner')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CWa54wMJuQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8f392470-c690-43f5-b3f2-af17be712ce2"
      },
      "source": [
        "train_class_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patientId</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>Target</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>264.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Lung Opacity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              patientId  ...                         class\n",
              "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6  ...  No Lung Opacity / Not Normal\n",
              "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd  ...  No Lung Opacity / Not Normal\n",
              "2  00322d4d-1c29-4943-afc9-b6754be640eb  ...  No Lung Opacity / Not Normal\n",
              "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5  ...                        Normal\n",
              "4  00436515-870c-4b36-a041-de91049b9ab4  ...                  Lung Opacity\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o80TB6UaNFfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill numeric rows with the zero\n",
        "for label, content in train_class_df.items():\n",
        "    if pd.api.types.is_numeric_dtype(content):\n",
        "        if pd.isnull(content).sum():\n",
        "             # Fill missing numeric values with median\n",
        "            train_class_df[label] = content.fillna(0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EASIEEX9OZPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8d5e398b-04c4-461f-b054-f02ea9d12531"
      },
      "source": [
        "# Check if there are any missing numberic values\n",
        "train_class_df.isna().sum()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "patientId    0\n",
              "x            0\n",
              "y            0\n",
              "width        0\n",
              "height       0\n",
              "Target       0\n",
              "class        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKA9vjKkdRGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_class_df.columns = ['image_name', 'xmin', 'ymin', 'xmax', 'ymax', 'class_id','class']"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncj50G_KJyfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2e66f0af-dde2-47f5-cc7a-39fc590b437c"
      },
      "source": [
        "train_class_df.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 37629 entries, 0 to 37628\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   image_name  37629 non-null  object \n",
            " 1   xmin        37629 non-null  float64\n",
            " 2   ymin        37629 non-null  float64\n",
            " 3   xmax        37629 non-null  float64\n",
            " 4   ymax        37629 non-null  float64\n",
            " 5   class_id    37629 non-null  int64  \n",
            " 6   class       37629 non-null  object \n",
            "dtypes: float64(4), int64(1), object(2)\n",
            "memory usage: 2.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOIYPwU6KuCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "560752d2-7805-46d2-c894-7510f5b4f6f1"
      },
      "source": [
        "train_class_df.drop_duplicates(subset=['image_name', 'xmin', 'ymin', 'xmax', 'ymax' ], keep='first', inplace=True)\n",
        "\n",
        "train_class_df.info()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 30227 entries, 0 to 37627\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   image_name  30227 non-null  object \n",
            " 1   xmin        30227 non-null  float64\n",
            " 2   ymin        30227 non-null  float64\n",
            " 3   xmax        30227 non-null  float64\n",
            " 4   ymax        30227 non-null  float64\n",
            " 5   class_id    30227 non-null  int64  \n",
            " 6   class       30227 non-null  object \n",
            "dtypes: float64(4), int64(1), object(2)\n",
            "memory usage: 1.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXhuNee4fa3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " train_class_df = train_class_df[train_class_df['class_id'] == 1]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utI_bPdXftgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c440ea6a-e84e-4728-939d-52a936c5e8f6"
      },
      "source": [
        "train_class_df.info()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 9555 entries, 4 to 37627\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   image_name  9555 non-null   object \n",
            " 1   xmin        9555 non-null   float64\n",
            " 2   ymin        9555 non-null   float64\n",
            " 3   xmax        9555 non-null   float64\n",
            " 4   ymax        9555 non-null   float64\n",
            " 5   class_id    9555 non-null   int64  \n",
            " 6   class       9555 non-null   object \n",
            "dtypes: float64(4), int64(1), object(2)\n",
            "memory usage: 597.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkWmCCwiay6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert float type to int\n",
        "for label, content in train_class_df.items():\n",
        "    if pd.api.types.is_float_dtype(content):\n",
        "      train_class_df[label] = train_class_df[label].astype(int)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETt_Tg4HchcA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "bb619602-44b0-43f9-f68b-1638c15fb51b"
      },
      "source": [
        "train_class_df.info()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 9555 entries, 4 to 37627\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   image_name  9555 non-null   object\n",
            " 1   xmin        9555 non-null   int64 \n",
            " 2   ymin        9555 non-null   int64 \n",
            " 3   xmax        9555 non-null   int64 \n",
            " 4   ymax        9555 non-null   int64 \n",
            " 5   class_id    9555 non-null   int64 \n",
            " 6   class       9555 non-null   object\n",
            "dtypes: int64(5), object(2)\n",
            "memory usage: 597.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnVeC528RLwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8cecd89c-5b22-4a47-c709-37343431b4a5"
      },
      "source": [
        "train_class_df = train_class_df[['image_name', 'class_id', 'xmin', 'ymin', 'xmax', 'ymax', 'class']]\n",
        "train_class_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>class_id</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>1</td>\n",
              "      <td>264</td>\n",
              "      <td>152</td>\n",
              "      <td>213</td>\n",
              "      <td>379</td>\n",
              "      <td>Lung Opacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>1</td>\n",
              "      <td>562</td>\n",
              "      <td>152</td>\n",
              "      <td>256</td>\n",
              "      <td>453</td>\n",
              "      <td>Lung Opacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
              "      <td>1</td>\n",
              "      <td>323</td>\n",
              "      <td>577</td>\n",
              "      <td>160</td>\n",
              "      <td>104</td>\n",
              "      <td>Lung Opacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
              "      <td>1</td>\n",
              "      <td>695</td>\n",
              "      <td>575</td>\n",
              "      <td>162</td>\n",
              "      <td>137</td>\n",
              "      <td>Lung Opacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>00aecb01-a116-45a2-956c-08d2fa55433f</td>\n",
              "      <td>1</td>\n",
              "      <td>288</td>\n",
              "      <td>322</td>\n",
              "      <td>94</td>\n",
              "      <td>135</td>\n",
              "      <td>Lung Opacity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              image_name  class_id  ...  ymax         class\n",
              "4   00436515-870c-4b36-a041-de91049b9ab4         1  ...   379  Lung Opacity\n",
              "6   00436515-870c-4b36-a041-de91049b9ab4         1  ...   453  Lung Opacity\n",
              "10  00704310-78a8-4b38-8475-49f4573b2dbb         1  ...   104  Lung Opacity\n",
              "12  00704310-78a8-4b38-8475-49f4573b2dbb         1  ...   137  Lung Opacity\n",
              "18  00aecb01-a116-45a2-956c-08d2fa55433f         1  ...   135  Lung Opacity\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPT7EfJmLKkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e6ddee21-7f7a-4ed7-b12c-2d662004548e"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create pathnames from image Patient ID's\n",
        "# The directories that contain the images.\n",
        "Data_Directory = \"/content/drive/My Drive/Pneumonia Detection\"\n",
        "images_dir      = os.path.join(Data_Directory,\"JPG_Train\")\n",
        "\n",
        "y = train_class_df['class']\n",
        "X = train_class_df.drop('class', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n",
        "\n",
        "print(\"\\nX_train:\\n\")\n",
        "print(X_train.head())\n",
        "print(X_train.shape)\n",
        "\n",
        "print(\"\\nX_test:\\n\")\n",
        "print(X_test.head())\n",
        "print(X_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "X_train:\n",
            "\n",
            "                                 image_name  class_id  xmin  ymin  xmax  ymax\n",
            "12883  6dc76e37-3793-4ef1-b0ae-e6fa2335e139         1   218   310   235   512\n",
            "30463  d974dbc0-5e7d-4aac-bda5-f29096aeeb5a         1    82   554   181   205\n",
            "7569   472dac2e-aba2-4119-b9f7-37939e23e0b1         1   194   461   286   276\n",
            "37474  3040d9d7-d895-453f-887c-616c10531960         1   641   576   241   183\n",
            "22542  ac512fbd-8e85-4cc8-9af2-fb035189a72c         1   618   380   203   189\n",
            "(7644, 6)\n",
            "\n",
            "X_test:\n",
            "\n",
            "                                 image_name  class_id  xmin  ymin  xmax  ymax\n",
            "2718   228b3dc1-f78a-4ac9-b213-2a416583d063         1   284   583   146   143\n",
            "4952   38c5dfe6-dcca-4bfd-85c1-f3868ab37c6a         1   154   316   205   295\n",
            "18335  90be7b6e-0db5-4395-843e-d38966f41412         1   102   336   300   614\n",
            "24283  b42eaeb8-b6d3-41d7-836c-56fd0922abf6         1   590   458   128   228\n",
            "26540  be27354e-3de7-4420-ae86-05fcc2e9218d         1   160   575   259   243\n",
            "(1911, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8r4jPCVMRH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.to_csv(PROJECT_DIR + '/labels_train.csv', index=False, header=False)\n",
        "X_test.to_csv(PROJECT_DIR + '/labels_val.csv', index=False, header=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IvYCuvdMTNO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "48156eee-e0ee-4b8f-eb6d-6db6dc6388e4"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>class_id</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12883</th>\n",
              "      <td>6dc76e37-3793-4ef1-b0ae-e6fa2335e139</td>\n",
              "      <td>1</td>\n",
              "      <td>218</td>\n",
              "      <td>310</td>\n",
              "      <td>235</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30463</th>\n",
              "      <td>d974dbc0-5e7d-4aac-bda5-f29096aeeb5a</td>\n",
              "      <td>1</td>\n",
              "      <td>82</td>\n",
              "      <td>554</td>\n",
              "      <td>181</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7569</th>\n",
              "      <td>472dac2e-aba2-4119-b9f7-37939e23e0b1</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "      <td>461</td>\n",
              "      <td>286</td>\n",
              "      <td>276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37474</th>\n",
              "      <td>3040d9d7-d895-453f-887c-616c10531960</td>\n",
              "      <td>1</td>\n",
              "      <td>641</td>\n",
              "      <td>576</td>\n",
              "      <td>241</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22542</th>\n",
              "      <td>ac512fbd-8e85-4cc8-9af2-fb035189a72c</td>\n",
              "      <td>1</td>\n",
              "      <td>618</td>\n",
              "      <td>380</td>\n",
              "      <td>203</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15920</th>\n",
              "      <td>819825bd-1bb0-4eef-9299-e2ae28531c2f</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>317</td>\n",
              "      <td>271</td>\n",
              "      <td>370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29137</th>\n",
              "      <td>cf8816d8-1032-4b78-8c15-27fbf3b1b763</td>\n",
              "      <td>1</td>\n",
              "      <td>596</td>\n",
              "      <td>431</td>\n",
              "      <td>333</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5711</th>\n",
              "      <td>3c4ab309-7722-4a52-a340-868b0417a0cc</td>\n",
              "      <td>1</td>\n",
              "      <td>305</td>\n",
              "      <td>498</td>\n",
              "      <td>142</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5376</th>\n",
              "      <td>3ae1c3de-e2a7-44f5-b794-b1ef71640d0f</td>\n",
              "      <td>1</td>\n",
              "      <td>183</td>\n",
              "      <td>504</td>\n",
              "      <td>223</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37594</th>\n",
              "      <td>c14d9ceb-019f-45f6-9299-281b58de57df</td>\n",
              "      <td>1</td>\n",
              "      <td>239</td>\n",
              "      <td>268</td>\n",
              "      <td>172</td>\n",
              "      <td>418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7644 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 image_name  class_id  xmin  ymin  xmax  ymax\n",
              "12883  6dc76e37-3793-4ef1-b0ae-e6fa2335e139         1   218   310   235   512\n",
              "30463  d974dbc0-5e7d-4aac-bda5-f29096aeeb5a         1    82   554   181   205\n",
              "7569   472dac2e-aba2-4119-b9f7-37939e23e0b1         1   194   461   286   276\n",
              "37474  3040d9d7-d895-453f-887c-616c10531960         1   641   576   241   183\n",
              "22542  ac512fbd-8e85-4cc8-9af2-fb035189a72c         1   618   380   203   189\n",
              "...                                     ...       ...   ...   ...   ...   ...\n",
              "15920  819825bd-1bb0-4eef-9299-e2ae28531c2f         1   135   317   271   370\n",
              "29137  cf8816d8-1032-4b78-8c15-27fbf3b1b763         1   596   431   333   207\n",
              "5711   3c4ab309-7722-4a52-a340-868b0417a0cc         1   305   498   142   121\n",
              "5376   3ae1c3de-e2a7-44f5-b794-b1ef71640d0f         1   183   504   223   149\n",
              "37594  c14d9ceb-019f-45f6-9299-281b58de57df         1   239   268   172   418\n",
              "\n",
              "[7644 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIqTsavnc9ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1u1Cj2_I08q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d6bd8fa-0357-41dd-d1be-1ead37ffd32f"
      },
      "source": [
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "# train_images_dir      = os.path.join(Data_Directory,\"JPG_Train\")\n",
        "# val_images_dir      = os.path.join(Data_Directory,\"JPG_test\")\n",
        "# #VOC_2012_images_dir      = '../../datasets/VOCdevkit/VOC2012/JPEGImages/'\n",
        "# csv_path_train  = os.path.join(Data_Directory,\"stage_2_train_labels.csv\")\n",
        "# csv_path_valid  = os.path.join(Data_Directory,\"stage_2_detailed_class_info.csv\")\n",
        "\n",
        "# # The XML parser needs to now what object class names to look for and in which order to map them to integers.\n",
        "# classes = ['background','No Pneumonia','Pneumonia']\n",
        "\n",
        "# train_dataset.parse_csv(train_images_dir,labels_filename=csv_path_train,input_format=['image_name','xmin','ymin','xmax','ymax','class_id'],include_classes='all',random_sample=False,ret=False,verbose=True)\n",
        "\n",
        "# val_dataset.parse_csv(val_images_dir,labels_filename=csv_path_valid,input_format=['image_name','xmin','ymin','xmax','ymax','class_id'],include_classes='all',random_sample=False,ret=False,verbose=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
        "\n",
        "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
        "\n",
        "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
        "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
        "\n",
        "# 2: Parse the image and label lists for the training and validation datasets.\n",
        "\n",
        "# TODO: Set the paths to your dataset here.\n",
        "\n",
        "# Images\n",
        "# images_dir = '/content/drive/My Drive/Pneumonia Detection/JPG_Train'\n",
        "\n",
        "Data_Directory = \"content/drive/My Drive/Pneumonia Detection\"\n",
        "\n",
        "images_dir      = os.path.join(Data_Directory, \"JPG_Train\")\n",
        "\n",
        "print(images_dir)\n",
        "\n",
        "# Ground truth\n",
        "train_labels_filename = os.path.join(PROJECT_DIR, 'labels_train.csv')\n",
        "val_labels_filename   = os.path.join(PROJECT_DIR, 'labels_val.csv')\n",
        "\n",
        "# The XML parser needs to now what object class names to look for and in which order to map them to integers.\n",
        "classes = ['background','No Pneumonia','Pneumonia']\n",
        "\n",
        "# train_dataset.parse_csv(images_dir=images_dir,\n",
        "#                         labels_filename=train_labels_filename,\n",
        "#                         input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
        "#                         include_classes='all')\n",
        "\n",
        "# val_dataset.parse_csv(images_dir=images_dir,\n",
        "#                       labels_filename=val_labels_filename,\n",
        "#                       input_format=['image_name', 'x', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
        "#                       include_classes='all')\n",
        "\n",
        "train_dataset.parse_csv(images_dir = images_dir,\n",
        "                        labels_filename=train_labels_filename,\n",
        "                        input_format=['image_name','xmin','ymin','xmax','ymax', 'class_id'],\n",
        "                        include_classes='all',\n",
        "                        random_sample=False,\n",
        "                        ret=False,\n",
        "                        verbose=True)\n",
        "\n",
        "val_dataset.parse_csv(images_dir = images_dir,\n",
        "                      labels_filename=val_labels_filename,\n",
        "                      input_format=['image_name', 'xmin','ymin','xmax','ymax', 'class_id'],\n",
        "                      include_classes='all',\n",
        "                      random_sample=False,\n",
        "                      ret=False,\n",
        "                      verbose=True)\n",
        "\n",
        "\n",
        "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
        "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
        "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
        "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
        "\n",
        "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
        "#                                   resize=False,\n",
        "#                                   variable_image_size=True,\n",
        "#                                   verbose=True)\n",
        "\n",
        "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
        "#                                 resize=False,\n",
        "#                                 variable_image_size=True,\n",
        "#                                 verbose=True)\n",
        "\n",
        "# # Get the number of samples in the training and validations datasets.\n",
        "# train_dataset_size = train_dataset.get_dataset_size()\n",
        "# val_dataset_size   = val_dataset.get_dataset_size()\n",
        "\n",
        "# print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
        "# print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "content/drive/My Drive/Pneumonia Detection/JPG_Train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcgig6qcW7BV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de83c393-3be0-4d51-c7a7-ce85612cf242"
      },
      "source": [
        "# 3: Set the batch size.\n",
        "\n",
        "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
        "\n",
        "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
        "\n",
        "# For the training generator:\n",
        "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
        "                                            img_width=img_width,\n",
        "                                            background=mean_color)\n",
        "\n",
        "# For the validation generator:\n",
        "convert_to_3_channels = ConvertTo3Channels()\n",
        "resize = Resize(height=img_height, width=img_width)\n",
        "\n",
        "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
        "\n",
        "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
        "predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
        "                   model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
        "                   model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
        "                   model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
        "                   model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
        "                   model.get_layer('conv9_2_mbox_conf').output_shape[1:3]]\n",
        "\n",
        "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
        "                                    img_width=img_width,\n",
        "                                    n_classes=n_classes,\n",
        "                                    predictor_sizes=predictor_sizes,\n",
        "                                    scales=scales,\n",
        "                                    aspect_ratios_per_layer=aspect_ratios,\n",
        "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                                    steps=steps,\n",
        "                                    offsets=offsets,\n",
        "                                    clip_boxes=clip_boxes,\n",
        "                                    variances=variances,\n",
        "                                    matching_type='multi',\n",
        "                                    pos_iou_threshold=0.5,\n",
        "                                    neg_iou_limit=0.5,\n",
        "                                    normalize_coords=normalize_coords)\n",
        "\n",
        "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
        "\n",
        "train_generator = train_dataset.generate(batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         transformations=[ssd_data_augmentation],\n",
        "                                         label_encoder=ssd_input_encoder,\n",
        "                                         returns={'processed_images',\n",
        "                                                  'encoded_labels'},\n",
        "                                         keep_images_without_gt=False)\n",
        "\n",
        "val_generator = val_dataset.generate(batch_size=batch_size,\n",
        "                                     shuffle=False,\n",
        "                                     transformations=[convert_to_3_channels,resize],\n",
        "                                     label_encoder=ssd_input_encoder,\n",
        "                                     returns={'processed_images',\n",
        "                                              'encoded_labels'},\n",
        "                                     keep_images_without_gt=False)\n",
        "\n",
        "# Get the number of samples in the training and validations datasets.\n",
        "train_dataset_size = train_dataset.get_dataset_size()\n",
        "val_dataset_size   = val_dataset.get_dataset_size()\n",
        "\n",
        "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size)) #7584\n",
        "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the training dataset:\t  5342\n",
            "Number of images in the validation dataset:\t  1765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paMkDshegBPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a learning rate schedule.\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 80:\n",
        "        return 0.001\n",
        "    elif epoch < 100:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6mTH20rpnQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model callbacks.\n",
        "\n",
        "# TODO: Set the filepath under which you want to save the model.\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(filepath='ssd300_pneumonia_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
        "                                   monitor='val_loss',\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True,\n",
        "                                   save_weights_only=False,\n",
        "                                   mode='auto',\n",
        "                                   period=1)\n",
        "#model_checkpoint.best = \n",
        "csv_logger = CSVLogger(filename='ssd300_pneumonia_training_log.csv',\n",
        "                       separator=',',\n",
        "                       append=True)\n",
        "\n",
        "\n",
        "\n",
        "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule)\n",
        "\n",
        "#terminate_on_nan = TerminateOnNaN()\n",
        "\n",
        "callbacks = [model_checkpoint,\n",
        "             csv_logger,\n",
        "             learning_rate_scheduler\n",
        "             ]\n",
        "             "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjf45a63prAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "c478dc94-9d97-4241-8863-08e1579d0995"
      },
      "source": [
        "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
        "initial_epoch   = 0\n",
        "final_epoch     = 1\n",
        "steps_per_epoch = 50\n",
        "\n",
        "\n",
        "# history = model.fit_generator(generator=train_generator,\n",
        "#                               steps_per_epoch=steps_per_epoch,\n",
        "#                               epochs=final_epoch,\n",
        "#                               callbacks=callbacks,\n",
        "#                               validation_data=val_generator,\n",
        "#                               validation_steps=ceil(val_dataset_size/batch_size),\n",
        "#                               verbose=1)\n",
        "                              \n",
        "\n",
        "\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch=steps_per_epoch,\n",
        "                              epochs=final_epoch,\n",
        "                              callbacks=callbacks,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
        "                              initial_epoch=initial_epoch,\n",
        "                              verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:838: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:561: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:825: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 612, in data_generator_task\n",
            "    generator_output = next(self._generator)\n",
            "  File \"/content/ssd_keras/data_generator/object_detection_2d_data_generator.py\", line 1016, in generate\n",
            "    with Image.open(filename) as image:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2809, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'content/drive/My Drive/Pneumonia Detection/JPG_Train/ae5bbcb2-8f3a-4f5c-a7b1-1ecaa6a7a967'\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-e05e262adf03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                               verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1863\u001b[0m                                          \u001b[0;34m'a tuple `(x, y, sample_weight)` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m                                          \u001b[0;34m'or `(x, y)`. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1866\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnYsBsehXp4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b79b6814-de0c-4a37-f1c6-5cf2aced642e"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ssd_keras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yvnHqOIptTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0b5462-0b62-4f11-dd43-ddee420844d0"
      },
      "source": [
        "!ls -lt /content/drive/My Drive/Pneumonia Detection/JPG_Train\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My': No such file or directory\n",
            "ls: cannot access 'Drive/Pneumonia': No such file or directory\n",
            "ls: cannot access 'Detection/JPG_Train': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC_Jbo5TXefI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}